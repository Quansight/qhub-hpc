{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IPyParallel Profile\n",
    "\n",
    "Borrowed from https://gist.github.com/basnijholt/c375ea2d1df6702492b619e0873d6c7c\n",
    "\n",
    "And https://docs.bodo.ai/latest/source/ipyparallel.html\n",
    "\n",
    "Overtime this will be automated and provide better slurm submission scripts\n",
    "\n",
    "The two main parts to edit here are \"mem\" and \"cpus-per-task\" in the last cell. These values will depend on the current structure of your HPC cluster. One approach is to have ipython worker use an entire node. Note that because of the way cloud providers measure memory, it helps to make the worker have 1GB less than the stated memory from the cloud provider.\n",
    "\n",
    "For example, a 8CPU 32GB instance we would set:\n",
    "```\n",
    "#SBATCH --mem=31G\n",
    "#SBATCH --cpus-per-task=8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ipython profile create --parallel --profile=slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/.ipython/profile_slurm/ipcontroller_config.py\n",
    "\n",
    "c.HubFactory.ip = u'*'\n",
    "c.HubFactory.registration_timeout = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/.ipython/profile_slurm/ipengine_config.py\n",
    "\n",
    "c.IPEngineApp.wait_for_url_file = 300\n",
    "c.EngineFactory.timeout = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOSTFILE=$(pwd)/hostfile.$SLURM_JOB_ID\n",
    "#scontrol show hostnames > $HOSTFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/.ipython/profile_slurm/ipcluster_config.py\n",
    "\n",
    "c.IPClusterStart.controller_launcher_class = 'SlurmControllerLauncher'\n",
    "c.IPClusterEngines.engine_launcher_class = 'SlurmEngineSetLauncher'\n",
    "\n",
    "# this is based on 4GB per core\n",
    "c.SlurmEngineSetLauncher.batch_template = \"\"\"#!/bin/sh\n",
    "#SBATCH --ntasks={n}\n",
    "#SBATCH --job-name=ipy-engine-\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=1\n",
    "\n",
    "HOSTFILE=$(pwd)/hostfile.$SLURM_JOB_ID\n",
    "scontrol show hostnames > $HOSTFILE\n",
    "\n",
    "mpiexec -n {n} -machinefile $HOSTFILE python -m ipyparallel.engine --mpi --profile-dir ~/.ipython/profile_slurm --cluster-id ''\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
